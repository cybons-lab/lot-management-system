"""
ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šè¨­å®š / SQLAlchemyã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†
"""

import logging
import os
import subprocess
from pathlib import Path
from typing import Generator

from sqlalchemy import create_engine, event, text
from sqlalchemy.orm import Session, sessionmaker

# ãƒ¢ãƒ‡ãƒ«ç™»éŒ²ï¼ˆinit_dbå†…ã§importã™ã‚‹ãŒã€å‹å‚ç…§ã®ãŸã‚ã“ã“ã«ã‚‚ç½®ã„ã¦å•é¡Œãªã—ï¼‰
from app.models.base_model import Base, set_sqlite_pragma
from .config import settings

logger = logging.getLogger(__name__)

# --- Engine ---------------------------------------------------------------
engine = create_engine(
    settings.DATABASE_URL,
    connect_args={"check_same_thread": False} if "sqlite" in settings.DATABASE_URL else {},
    echo=settings.ENVIRONMENT == "development",  # é–‹ç™ºæ™‚ã¯SQLãƒ­ã‚°
)
if engine.dialect.name == "sqlite":
    event.listen(engine, "connect", set_sqlite_pragma)

# --- Session --------------------------------------------------------------
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)


def get_db() -> Generator[Session, None, None]:
    """FastAPI ä¾å­˜æ€§æ³¨å…¥ç”¨ã®DBã‚»ãƒƒã‚·ãƒ§ãƒ³"""
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()


# --- Schema lifecycle -----------------------------------------------------
def init_db() -> None:
    """
    DBåˆæœŸåŒ–ï¼ˆãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆã¯Alembicã«å§”è­²ï¼‰
    Alembicãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã—ã¦ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆã—ã¾ã™
    """
    import app.models  # noqa: F401  ãƒ¢ãƒ‡ãƒ«ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€ãŸã‚ã®å‰¯ä½œç”¨import

    # Alembicãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã—ã¦ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆ
    try:
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆalembic.iniãŒã‚ã‚‹å ´æ‰€ï¼‰
        backend_dir = Path(__file__).parent.parent.parent

        logger.info("ğŸ”„ Running Alembic migrations to create tables...")
        result = subprocess.run(
            ["alembic", "upgrade", "head"],
            cwd=backend_dir,
            capture_output=True,
            text=True,
            check=True
        )
        logger.info("âœ… Alembic migrations completed successfully")
        if result.stdout:
            logger.debug(f"Alembic output: {result.stdout}")
    except subprocess.CalledProcessError as e:
        logger.error(f"âŒ Alembic migration failed: {e}")
        logger.error(f"stdout: {e.stdout}")
        logger.error(f"stderr: {e.stderr}")
        raise RuntimeError(f"Failed to run Alembic migrations: {e.stderr}")
    except Exception as e:
        logger.error(f"âŒ Unexpected error running Alembic: {e}")
        raise


def _drop_dependent_views() -> None:
    """
    ãƒ†ãƒ¼ãƒ–ãƒ«ä¾å­˜ã®VIEWã‚’å…ˆã«DROPã™ã‚‹ã€‚
    ä¾å­˜ã§è½ã¡ã‚‹ä»£è¡¨VIEWã‚’ã“ã“ã¸åˆ—æŒ™ã€‚å­˜åœ¨ã—ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ã€‚
    """
    if "sqlite" in settings.DATABASE_URL:
        return

    dependent_views = [
        # åœ¨åº«é›†è¨ˆãƒ“ãƒ¥ãƒ¼ï¼ˆStockMovementã«ä¾å­˜ï¼‰
        "lot_current_stock",
        # è¿½åŠ ã®VIEWãŒã‚ã‚Œã°ã“ã“ã«è¿½è¨˜
        # "lot_daily_stock",
    ]

    with engine.begin() as conn:
        for view_name in dependent_views:
            try:
                conn.execute(text(f'DROP VIEW IF EXISTS {view_name} CASCADE'))
                logger.info(f"ğŸ—‘ï¸ Dropped view: {view_name}")
            except Exception as e:
                logger.warning(f"âš ï¸ VIEWå‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸ ({view_name}): {e}")


def drop_db() -> None:
    """
    ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å‰Šé™¤ï¼ˆé–‹ç™º/æ¤œè¨¼ç”¨é€”ï¼‰
    - SQLite: ç‰©ç†ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
    - PostgreSQL: ã‚¹ã‚­ãƒ¼ãƒ public ã‚’ CASCADE ã§è½ã¨ã—ã¦å†ä½œæˆ
    """
    if settings.ENVIRONMENT == "production":
        raise ValueError("æœ¬ç•ªç’°å¢ƒã§ã¯ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å‰Šé™¤ã¯ã§ãã¾ã›ã‚“")

    # SQLite: ç‰©ç†ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ï¼ˆå¾“æ¥ã©ãŠã‚Šï¼‰
    if "sqlite" in settings.DATABASE_URL:
        engine.dispose()
        try:
            db_path_str = settings.DATABASE_URL.split(":///")[1]
        except IndexError:
            return
        db_path = Path(db_path_str)
        if db_path.exists():
            os.remove(db_path)
            logger.info("ğŸ—‘ï¸ Deleted SQLite database file")
        return

    # PostgreSQL: ã‚¹ã‚­ãƒ¼ãƒã”ã¨åˆæœŸåŒ–
    logger.info("ğŸ—‘ï¸ Dropping and recreating schema 'public'...")
    with engine.begin() as conn:
        # å¿…è¦ãªã‚‰åˆ¥ã‚¹ã‚­ãƒ¼ãƒåã«å¤‰æ›´ï¼ˆé€šå¸¸ã¯ publicï¼‰
        schema = "public"
        conn.execute(text(f'DROP SCHEMA IF EXISTS "{schema}" CASCADE;'))
        conn.execute(text(f'CREATE SCHEMA "{schema}";'))
        # æ¤œç´¢ãƒ‘ã‚¹ã‚’æˆ»ã™ï¼ˆä»»æ„ï¼‰
        conn.execute(text(f'SET search_path TO "{schema}";'))
        logger.info(f"âœ… Schema '{schema}' has been recreated")

    # æ¥ç¶šãƒ—ãƒ¼ãƒ«ã‚’ç ´æ£„
    engine.dispose()
    logger.info("â„¹ï¸ DBã‚¨ãƒ³ã‚¸ãƒ³ã‚’ç ´æ£„ã—ã¾ã—ãŸ (æ¥ç¶šãƒ—ãƒ¼ãƒ«ã‚’ã‚¯ãƒ­ãƒ¼ã‚º)")
